<!DOCTYPE html><html lang="en" class="scroll-smooth"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" href="/bio.jpg"/><link rel="stylesheet" href="/_next/static/css/8d8cb1d19c5af398.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-679b75d1c4c2027c.js"/><script src="/_next/static/chunks/4bd1b696-70b6d399998de86a.js" async=""></script><script src="/_next/static/chunks/684-50096e198fb40285.js" async=""></script><script src="/_next/static/chunks/main-app-eac09b99547011a3.js" async=""></script><script src="/_next/static/chunks/161-26b68443731f0363.js" async=""></script><script src="/_next/static/chunks/874-196dbf0660d69360.js" async=""></script><script src="/_next/static/chunks/560-dc25b2d8b8d763b3.js" async=""></script><script src="/_next/static/chunks/app/layout-282c794e5abd4727.js" async=""></script><script src="/_next/static/chunks/679-23c4484ac046c23c.js" async=""></script><script src="/_next/static/chunks/748-390a51461d87cd71.js" async=""></script><script src="/_next/static/chunks/app/page-79095d1491d82e47.js" async=""></script><link rel="icon" href="/favicon.png" type="image/svg+xml"/><link rel="dns-prefetch" href="https://google-fonts.jialeliu.com"/><link rel="preconnect" href="https://google-fonts.jialeliu.com" crossorigin=""/><link rel="preload" as="style" href="https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&amp;family=Crimson+Text:ital,wght@0,400;0,600;1,400&amp;display=swap"/><link rel="stylesheet" id="gfonts-css" href="https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&amp;family=Crimson+Text:ital,wght@0,400;0,600;1,400&amp;display=swap" media="print"/><script>
              (function(){
                var l = document.getElementById('gfonts-css');
                if (!l) return;
                if (l.media !== 'all') {
                  l.addEventListener('load', function(){ try { l.media = 'all'; } catch(e){} });
                }
              })();
            </script><noscript><link rel="stylesheet" href="https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&amp;family=Crimson+Text:ital,wght@0,400;0,600;1,400&amp;display=swap"/></noscript><script>
              try {
                const theme = localStorage.getItem('theme-storage');
                const parsed = theme ? JSON.parse(theme) : null;
                const setting = parsed?.state?.theme || 'system';
                const prefersDark = typeof window !== 'undefined' && window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));
                var root = document.documentElement;
                root.classList.add(effective);
                root.setAttribute('data-theme', effective);
              } catch (e) {
                var root = document.documentElement;
                root.classList.add('light');
                root.setAttribute('data-theme', 'light');
              }
            </script><title>Di Huang</title><meta name="description" content="Associate Professor at ICT, CAS."/><meta name="author" content="Di Huang"/><meta name="keywords" content="Di Huang,PhD,Research,ICT, CAS"/><meta name="creator" content="Di Huang"/><meta name="publisher" content="Di Huang"/><meta property="og:title" content="Di Huang"/><meta property="og:description" content="Associate Professor at ICT, CAS."/><meta property="og:site_name" content="Di Huang&#x27;s Academic Website"/><meta property="og:locale" content="en_US"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Di Huang"/><meta name="twitter:description" content="Associate Professor at ICT, CAS."/><link rel="icon" href="/favicon.png"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="font-sans antialiased"><div style="visibility:hidden"><nav class="fixed top-0 left-0 right-0 z-50" data-headlessui-state=""><div class="transition-all duration-300 ease-out bg-transparent" style="transform:translateY(-100px)"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex justify-between items-center h-16 lg:h-20"><div class="flex-shrink-0" tabindex="0"><a class="text-xl lg:text-2xl font-serif font-semibold text-primary hover:text-accent transition-colors duration-200" href="/">Di Huang</a></div><div class="hidden lg:block"><div class="ml-10 flex items-center space-x-8"><div class="flex items-baseline space-x-8"><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-primary" href="/"><span class="relative z-10">About</span><div class="absolute inset-0 bg-accent/10 rounded-lg"></div></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/publications/"><span class="relative z-10">Publications</span></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/teaching/"><span class="relative z-10">Teaching</span></a></div><div class="flex items-center justify-center w-10 h-10 rounded-lg border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] bg-background dark:bg-neutral-800"><div class="w-4 h-4 rounded-full bg-neutral-300 animate-pulse"></div></div></div></div><div class="lg:hidden flex items-center space-x-2"><div class="flex items-center justify-center w-10 h-10 rounded-lg border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] bg-background dark:bg-neutral-800"><div class="w-4 h-4 rounded-full bg-neutral-300 animate-pulse"></div></div><button class="inline-flex items-center justify-center p-2 rounded-md text-neutral-600 hover:text-primary hover:bg-neutral-100 dark:hover:bg-neutral-800 focus:outline-none focus:ring-2 focus:ring-inset focus:ring-accent transition-colors duration-200" id="headlessui-disclosure-button-Â«R5pdbÂ»" type="button" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Open main menu</span><div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="block h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></div></button></div></div></div></div></nav><main class="min-h-screen pt-16 lg:pt-20"><div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-8 bg-background min-h-screen"><div class="grid grid-cols-1 lg:grid-cols-3 gap-12"><div class="lg:col-span-1"><div class="sticky top-8" style="opacity:0;transform:translateY(20px)"><div class="w-64 h-64 mx-auto mb-6 rounded-2xl overflow-hidden shadow-lg hover:shadow-xl transition-all duration-200 hover:scale-105"><img alt="Di Huang" width="256" height="256" decoding="async" data-nimg="1" class="w-full h-full object-cover object-[32%_center]" style="color:transparent" src="/bio.jpg"/></div><div class="text-center mb-6"><h1 class="text-3xl font-serif font-bold text-primary mb-2">Di Huang</h1><p class="text-lg text-accent font-medium mb-1">Associate Professor</p><p class="text-neutral-600 mb-2">ICT, CAS</p></div><div class="flex flex-wrap justify-center gap-3 sm:gap-4 mb-6 relative px-2"><div class="relative"><button class="p-2 sm:p-2 transition-colors duration-200 text-neutral-600 dark:text-neutral-400 hover:text-accent" aria-label="Email"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-5 w-5"><path stroke-linecap="round" stroke-linejoin="round" d="M21.75 6.75v10.5a2.25 2.25 0 0 1-2.25 2.25h-15a2.25 2.25 0 0 1-2.25-2.25V6.75m19.5 0A2.25 2.25 0 0 0 19.5 4.5h-15a2.25 2.25 0 0 0-2.25 2.25m19.5 0v.243a2.25 2.25 0 0 1-1.07 1.916l-7.5 4.615a2.25 2.25 0 0 1-2.36 0L3.32 8.91a2.25 2.25 0 0 1-1.07-1.916V6.75"></path></svg></button></div><div class="relative"><button class="p-2 sm:p-2 transition-colors duration-200 text-neutral-600 dark:text-neutral-400 hover:text-accent" aria-label="Location"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-5 w-5"><path stroke-linecap="round" stroke-linejoin="round" d="M15 10.5a3 3 0 1 1-6 0 3 3 0 0 1 6 0Z"></path><path stroke-linecap="round" stroke-linejoin="round" d="M19.5 10.5c0 7.142-7.5 11.25-7.5 11.25S4.5 17.642 4.5 10.5a7.5 7.5 0 1 1 15 0Z"></path></svg></button></div><a href="https://scholar.google.com/citations?user=i27zCWQAAAAJ&amp;hl=en&amp;oi=sra" target="_blank" rel="noopener noreferrer" class="p-2 sm:p-2 text-neutral-600 dark:text-neutral-400 hover:text-accent transition-colors duration-200" aria-label="Google Scholar"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-5 w-5"><path stroke-linecap="round" stroke-linejoin="round" d="M4.26 10.147a60.438 60.438 0 0 0-.491 6.347A48.62 48.62 0 0 1 12 20.904a48.62 48.62 0 0 1 8.232-4.41 60.46 60.46 0 0 0-.491-6.347m-15.482 0a50.636 50.636 0 0 0-2.658-.813A59.906 59.906 0 0 1 12 3.493a59.903 59.903 0 0 1 10.399 5.84c-.896.248-1.783.52-2.658.814m-15.482 0A50.717 50.717 0 0 1 12 13.489a50.702 50.702 0 0 1 7.74-3.342M6.75 15a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm0 0v-3.675A55.378 55.378 0 0 1 12 8.443m-7.007 11.55A5.981 5.981 0 0 0 6.75 15.75v-1.5"></path></svg></a><a href="https://github.com/huangdi95" target="_blank" rel="noopener noreferrer" class="p-2 sm:p-2 text-neutral-600 dark:text-neutral-400 hover:text-accent transition-colors duration-200" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-5 w-5" aria-hidden="true"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a></div><div class="bg-neutral-100 dark:bg-neutral-800 rounded-lg p-4 mb-6 hover:shadow-lg transition-all duration-200 hover:scale-[1.02]"><h3 class="font-semibold text-primary mb-3">Research Interests</h3><div class="space-y-2 text-sm text-neutral-700 dark:text-neutral-500"><div>Automated Chip Design</div><div>Program Synthesis and Code Generation</div><div>Large Language Models</div></div></div><div class="flex justify-center"><div class="relative"><button class="flex items-center space-x-2 px-4 py-2 rounded-lg font-medium text-sm transition-all duration-200 bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-500 hover:bg-red-50 dark:hover:bg-red-900/20 hover:text-red-600 dark:hover:text-red-400 cursor-pointer" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-4 w-4"><path stroke-linecap="round" stroke-linejoin="round" d="M21 8.25c0-2.485-2.099-4.5-4.688-4.5-1.935 0-3.597 1.126-4.312 2.733-.715-1.607-2.377-2.733-4.313-2.733C5.1 3.75 3 5.765 3 8.25c0 7.22 9 12 9 12s9-4.78 9-12Z"></path></svg><span>Like</span></button></div></div></div></div><div class="lg:col-span-2 space-y-8"><section id="about" class="scroll-mt-24 space-y-8"><section style="opacity:0;transform:translateY(20px)"><h2 class="text-2xl font-serif font-bold text-primary mb-4">About</h2><div class="text-neutral-700 dark:text-neutral-600 leading-relaxed"><p class="mb-4 last:mb-0">I am an Associate Professor at Institute of Computing Technology, Chinese Academy of Sciences (ICT, CAS). I received my B.S. in Physics from Tsinghua University and my Ph.D. from ICT, CAS. My research focuses on automated chip design and code generation, with particular interest in <strong class="font-semibold text-primary">systematically training chip design foundation models and building practical chip design systems powered by these models</strong>. I am also broadly interested in <strong class="font-semibold text-primary">Embodied AI</strong>.</p>
<p class="mb-4 last:mb-0">I am the lead contributor to the <a href="https://yyyangzhao.github.io/CodeV-Series/" node="[object Object]" target="_blank" rel="noopener noreferrer" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm">CodeV series</a>, a family of fully open-source foundation models for HDL (e.g., Verilog) generation.</p>
<p class="mb-4 last:mb-0">Feel free to reach me at <strong class="font-semibold text-primary">huangdi[AT]ict.ac.cn</strong>.</p></div></section><section style="opacity:0;transform:translateY(20px)"><h2 class="text-2xl font-serif font-bold text-primary mb-4">News</h2><div class="space-y-3"><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">2025-11</span><div class="prose prose-neutral dark:prose-invert max-w-none"><p>4 papers were accepted to <a href="https://aaai.org/conference/aaai/aaai-26/" node="[object Object]" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm" target="_blank" rel="noopener noreferrer">AAAI 2026</a> <span class="text-red-500 font-semibold">(2 oral)</span> ðŸŽ‰</p></div></div><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">2025-10</span><div class="prose prose-neutral dark:prose-invert max-w-none"><p>2 papers were accepted to <a href="https://ieee-ceda.org/publications/tcad/" node="[object Object]" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm" target="_blank" rel="noopener noreferrer">IEEE TCAD</a> ðŸŽ‰</p></div></div><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">2025-09</span><div class="prose prose-neutral dark:prose-invert max-w-none"><p>We have open-sourced our HDL generation foundation models <a href="https://huggingface.co/collections/zhuyaoyu/codev-series" node="[object Object]" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm" target="_blank" rel="noopener noreferrer">CodeV series</a> on <a href="https://huggingface.co/" node="[object Object]" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm" target="_blank" rel="noopener noreferrer">ðŸ¤—Hugging Face</a>, along with their <a href="https://huggingface.co/collections/zhuyaoyu/codev-series" node="[object Object]" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm" target="_blank" rel="noopener noreferrer">datasets</a>ðŸ”¥ðŸ”¥ðŸ”¥</p></div></div><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">2025-09</span><div class="prose prose-neutral dark:prose-invert max-w-none"><p>4 papers were accepted to <a href="https://neurips.cc/Conferences/2025" node="[object Object]" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm" target="_blank" rel="noopener noreferrer">NeurIPS 2025</a> <span class="text-red-500 font-semibold">(1 spotlight)</span> ðŸŽ‰</p></div></div></div></section><section style="opacity:0;transform:translateY(20px)"><div class="flex items-center justify-between mb-4"><h2 class="text-2xl font-serif font-bold text-primary">Selected Publications</h2><a class="text-accent hover:text-accent-dark text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm" href="/publications/">View All â†’</a></div><div class="space-y-4"><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-700 w-full aspect-video md:aspect-auto md:h-full"><img alt="StepFun-Formalizer: Unlocking the Autoformalization Potential of LLMs through Knowledge-Reasoning Fusion" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/stepfun-formalizer.png"/></div></div><div class="flex-1 flex flex-col"><h3 class="font-semibold text-primary mb-2 leading-tight">StepFun-Formalizer: Unlocking the Autoformalization Potential of LLMs through Knowledge-Reasoning Fusion</h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class=" 
                                                    ">Yutong Wu</span>, </span><span><span class="font-semibold text-accent 
                                                    ">Di Huang</span>, </span><span><span class=" 
                                                    ">Ruosi Wan</span>, </span><span><span class=" 
                                                    ">Yue Peng</span>, </span><span><span class=" 
                                                    ">Shijie Shang</span>, </span><span><span class=" 
                                                    ">Chenrui Cao</span>, </span><span><span class=" 
                                                    ">Lei Qi</span>, </span><span><span class=" 
                                                    ">Rui Zhang</span>, </span><span><span class=" 
                                                    ">Zidong Du</span>, </span><span><span class=" 
                                                    ">Jie Yan</span>, </span><span><span class=" 
                                                    ">Xing Hu</span></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2"><span>AAAI 2026 </span><span class="text-red-600 font-bold dark:text-red-400">Oral</span></p><div class="flex flex-wrap gap-2 mt-auto pt-2"><a href="https://arxiv.org/abs/2508.04440" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a><a href="https://huggingface.co/collections/stepfun-ai/stepfun-formalizer" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Model</a></div></div></div></div><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-700 w-full aspect-video md:aspect-auto md:h-full"><img alt="AGON: Automated Design Framework for Customizing Processors from ISA Documents" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/agon.png"/></div></div><div class="flex-1 flex flex-col"><h3 class="font-semibold text-primary mb-2 leading-tight">AGON: Automated Design Framework for Customizing Processors from ISA Documents</h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class=" 
                                                    ">Chongxiao Li</span>, </span><span><span class="font-semibold text-accent 
                                                    ">Di Huang</span>, </span><span><span class=" 
                                                    ">Pengwei Jin</span>, </span><span><span class=" 
                                                    ">Tianyun Ma</span>, </span><span><span class=" 
                                                    ">Husheng Han</span>, </span><span><span class=" 
                                                    ">Shuyao Cheng</span>, </span><span><span class=" 
                                                    ">Yifan Hao</span>, </span><span><span class=" 
                                                    ">Yongwei Zhao</span>, </span><span><span class=" 
                                                    ">Guanglin Xu</span>, </span><span><span class=" 
                                                    ">Zidong Du</span>, </span><span><span class=" 
                                                    ">Rui Zhang</span>, </span><span><span class=" 
                                                    ">Xiaqing Li</span>, </span><span><span class=" 
                                                    ">Yuanbo Wen</span>, </span><span><span class=" 
                                                    ">Xing Hu</span>, </span><span><span class=" 
                                                    ">Qi Guo</span></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2"><span>IEEE TCAD 2025</span></p><div class="flex flex-wrap gap-2 mt-auto pt-2"><a href="https://arxiv.org/abs/2412.20954" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a></div></div></div></div><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-700 w-full aspect-video md:aspect-auto md:h-full"><img alt="MigGPT: Harnessing Large Language Models for Automated Migration of Out-of-Tree Linux Kernel Patches Across Versions" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/miggpt.png"/></div></div><div class="flex-1 flex flex-col"><h3 class="font-semibold text-primary mb-2 leading-tight">MigGPT: Harnessing Large Language Models for Automated Migration of Out-of-Tree Linux Kernel Patches Across Versions</h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class=" 
                                                    ">Pucheng Dang</span>, </span><span><span class="font-semibold text-accent 
                                                    ">Di Huang</span>, </span><span><span class=" 
                                                    ">Dong Li</span>, </span><span><span class=" 
                                                    ">Kang Chen</span>, </span><span><span class=" 
                                                    ">Yuanbo Wen</span>, </span><span><span class=" 
                                                    ">Qi Guo</span>, </span><span><span class=" 
                                                    ">Xing Hu</span></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2"><span>NeurIPS 2025 </span><span class="text-red-600 font-bold dark:text-red-400">Spotlight</span></p><div class="flex flex-wrap gap-2 mt-auto pt-2"><a href="https://arxiv.org/abs/2504.09474" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a></div></div></div></div><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-700 w-full aspect-video md:aspect-auto md:h-full"><img alt="CodeV: Empowering LLMs with HDL Generation through Multi-Level Summarization" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/codev.gif"/></div></div><div class="flex-1 flex flex-col"><h3 class="font-semibold text-primary mb-2 leading-tight">CodeV: Empowering LLMs with HDL Generation through Multi-Level Summarization</h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class=" 
                                                    ">Yang Zhao</span>, </span><span><span class="font-semibold text-accent 
                                                    ">Di Huang</span>, </span><span><span class=" 
                                                    ">Chongxiao Li</span>, </span><span><span class=" 
                                                    ">Pengwei Jin</span>, </span><span><span class=" 
                                                    ">Muxin Song</span>, </span><span><span class=" 
                                                    ">Yinan Xu</span>, </span><span><span class=" 
                                                    ">Ziyuan Nan</span>, </span><span><span class=" 
                                                    ">Mingju Gao</span>, </span><span><span class=" 
                                                    ">Tianyun Ma</span>, </span><span><span class=" 
                                                    ">Lei Qi</span>, </span><span><span class=" 
                                                    ">Yansong Pan</span>, </span><span><span class=" 
                                                    ">Zhenxing Zhang</span>, </span><span><span class=" 
                                                    ">Rui Zhang</span>, </span><span><span class=" 
                                                    ">Xishan Zhang</span>, </span><span><span class=" 
                                                    ">Zidong Du</span>, </span><span><span class=" 
                                                    ">Xing Hu</span></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2"><span>IEEE TCAD 2025</span></p><div class="flex flex-wrap gap-2 mt-auto pt-2"><a href="https://iprc-dip.github.io/CodeV/" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Project Page</a><a href="https://arxiv.org/abs/2407.10424v5" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a><a href="https://github.com/IPRC-DIP/CodeV" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Code</a><a href="https://huggingface.co/datasets/yang-z/CodeV-All-dataset" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Data</a><a href="https://huggingface.co/collections/zhuyaoyu/codev-series" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Model</a></div></div></div></div><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-700 w-full aspect-video md:aspect-auto md:h-full"><img alt="RealBench: Benchmarking Verilog Generation Models with Real-World IP Designs" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/realbench.gif"/></div></div><div class="flex-1 flex flex-col"><h3 class="font-semibold text-primary mb-2 leading-tight">RealBench: Benchmarking Verilog Generation Models with Real-World IP Designs</h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class=" 
                                                    ">Pengwei Jin</span>, </span><span><span class="font-semibold text-accent 
                                                    ">Di Huang</span>, </span><span><span class=" 
                                                    ">Chongxiao Li</span>, </span><span><span class=" 
                                                    ">Shuyao Cheng</span>, </span><span><span class=" 
                                                    ">Yang Zhao</span>, </span><span><span class=" 
                                                    ">Xinyao Zheng</span>, </span><span><span class=" 
                                                    ">Jiaguo Zhu</span>, </span><span><span class=" 
                                                    ">Shuyi Xing</span>, </span><span><span class=" 
                                                    ">Bohan Dou</span>, </span><span><span class=" 
                                                    ">Rui Zhang</span>, </span><span><span class=" 
                                                    ">Zidong Du</span>, </span><span><span class=" 
                                                    ">Xing Hu</span></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2"><span>Preprint</span></p><div class="flex flex-wrap gap-2 mt-auto pt-2"><a href="https://arxiv.org/abs/2507.16200" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a><a href="https://github.com/IPRC-DIP/RealBench" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Code</a><a href="https://huggingface.co/datasets/Pengwei-Jin/RealBench" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Data</a></div></div></div></div><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-700 w-full aspect-video md:aspect-auto md:h-full"><img alt="QiMeng-CodeV-R1: Reasoning-Enhanced Verilog Generation" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/codev-r1.png"/></div></div><div class="flex-1 flex flex-col"><h3 class="font-semibold text-primary mb-2 leading-tight">QiMeng-CodeV-R1: Reasoning-Enhanced Verilog Generation</h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class=" 
                                                    ">Yaoyu Zhu</span>, </span><span><span class="font-semibold text-accent 
                                                    ">Di Huang</span>, </span><span><span class=" 
                                                    ">Hanqi Lyu</span>, </span><span><span class=" 
                                                    ">Xiaoyun Zhang</span>, </span><span><span class=" 
                                                    ">Chongxiao Li</span>, </span><span><span class=" 
                                                    ">Wenxuan Shi</span>, </span><span><span class=" 
                                                    ">Yutong Wu</span>, </span><span><span class=" 
                                                    ">Jianan Mu</span>, </span><span><span class=" 
                                                    ">Jinghua Wang</span>, </span><span><span class=" 
                                                    ">Pengwei Jin</span>, </span><span><span class=" 
                                                    ">Shuyao Cheng</span>, </span><span><span class=" 
                                                    ">Shengwen Liang</span>, </span><span><span class=" 
                                                    ">Xishan Zhang</span>, </span><span><span class=" 
                                                    ">Rui Zhang</span>, </span><span><span class=" 
                                                    ">Zidong Du</span>, </span><span><span class=" 
                                                    ">Qi Guo</span>, </span><span><span class=" 
                                                    ">Xing Hu</span>, </span><span><span class=" 
                                                    ">Yunji Chen</span></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2"><span>NeurIPS 2025</span></p><div class="flex flex-wrap gap-2 mt-auto pt-2"><a href="https://iprc-dip.github.io/CodeV-R1/" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Project Page</a><a href="https://arxiv.org/abs/2505.24183" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a><a href="https://github.com/IPRC-DIP/CodeV-R1" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Code</a><a href="https://huggingface.co/datasets/zhuyaoyu/CodeV-R1-dataset" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Data</a><a href="https://huggingface.co/collections/zhuyaoyu/codev-series" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Model</a></div></div></div></div><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-700 w-full aspect-video md:aspect-auto md:h-full"><img alt="ANPL: Towards Natural Programming with Interactive Decomposition" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/anpl.png"/></div></div><div class="flex-1 flex flex-col"><h3 class="font-semibold text-primary mb-2 leading-tight">ANPL: Towards Natural Programming with Interactive Decomposition</h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class="font-semibold text-accent 
                                                    ">Di Huang</span>, </span><span><span class=" 
                                                    ">Ziyuan Nan</span>, </span><span><span class=" 
                                                    ">Xing Hu</span>, </span><span><span class=" 
                                                    ">Pengwei Jin</span>, </span><span><span class=" 
                                                    ">Shaohui Peng</span>, </span><span><span class=" 
                                                    ">Yuanbo Wen</span>, </span><span><span class=" 
                                                    ">Rui Zhang</span>, </span><span><span class=" 
                                                    ">Zidong Du</span>, </span><span><span class=" 
                                                    ">Qi Guo</span>, </span><span><span class=" 
                                                    ">Yewen Pu</span>, </span><span><span class=" 
                                                    ">Yunji Chen</span></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2"><span>NeurIPS 2023</span></p><div class="flex flex-wrap gap-2 mt-auto pt-2"><a href="https://iprc-dip.github.io/ANPL/" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Project Page</a><a href="https://arxiv.org/abs/2305.18498" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a><a href="https://github.com/IPRC-DIP/ANPL" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Code</a><a href="https://github.com/IPRC-DIP/DARC/releases/tag/dataset" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Data</a></div></div></div></div><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-700 w-full aspect-video md:aspect-auto md:h-full"><img alt="Neural Program Synthesis with Query" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/query.png"/></div></div><div class="flex-1 flex flex-col"><h3 class="font-semibold text-primary mb-2 leading-tight">Neural Program Synthesis with Query</h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class="font-semibold text-accent 
                                                    ">Di Huang</span>, </span><span><span class=" 
                                                    ">Rui Zhang</span>, </span><span><span class=" 
                                                    ">Xing Hu</span>, </span><span><span class=" 
                                                    ">Xishan Zhang</span>, </span><span><span class=" 
                                                    ">Pengwei Jin</span>, </span><span><span class=" 
                                                    ">Nan Li</span>, </span><span><span class=" 
                                                    ">Zidong Du</span>, </span><span><span class=" 
                                                    ">Qi Guo</span>, </span><span><span class=" 
                                                    ">Yunji Chen</span></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2"><span>ICLR 2022</span></p><div class="flex flex-wrap gap-2 mt-auto pt-2"><a href="https://arxiv.org/abs/2205.07857" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-700 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a></div></div></div></div></div></section><section style="opacity:0;transform:translateY(20px)"><h2 class="text-2xl font-serif font-bold text-primary mb-4">Services</h2><div class="space-y-3"><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">Reviewer</span><div class="prose prose-neutral dark:prose-invert max-w-none"><p>Neurips 2023-, ICLR 2024-, ICML 2024-, AAAI 2025-, AISTATS 2025</p></div></div><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">Organizing Committee</span><div class="prose prose-neutral dark:prose-invert max-w-none"><p><a href="https://ai4facd.github.io/2024/" node="[object Object]" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm" target="_blank" rel="noopener noreferrer">AI for Fully-Automated Chip Design (AI4FACD) Workshop</a> @ <a href="https://iscaconf.org/isca2024/" node="[object Object]" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm" target="_blank" rel="noopener noreferrer">ISCA 2024</a></p></div></div></div></section><section style="opacity:0;transform:translateY(20px)"><h2 class="text-2xl font-serif font-bold text-primary mb-4">Invited Talks</h2><div class="space-y-3"><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">2025-09</span><div class="prose prose-neutral dark:prose-invert max-w-none"><p>LLM for Hardware Code Generation and Optimization @ <a href="https://conf.ccf.org.cn/web/api/m1406937421697912832175548162096.action" node="[object Object]" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm" target="_blank" rel="noopener noreferrer">CCF ADL</a></p></div></div><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">2025-06</span><div class="prose prose-neutral dark:prose-invert max-w-none"><p>QiMeng: Automated Hardware and Software Design for Processor Chip @ <a href="https://ai4facd.github.io/2025/" node="[object Object]" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm" target="_blank" rel="noopener noreferrer">AI4FACD Workshop</a> @ <a href="https://iscaconf.org/isca2025/" node="[object Object]" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm" target="_blank" rel="noopener noreferrer">ISCA 2025</a>:</p></div></div></div></section></section></div></div><div class="flex justify-center py-8 w-full bg-background"></div></div><!--$--><!--/$--><!--$--><!--/$--></main><footer class="border-t border-neutral-200/50 bg-neutral-50/50 dark:bg-neutral-900/50 dark:border-neutral-700/50"><div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-6"><div class="flex flex-col sm:flex-row justify-between items-center gap-2"><p class="text-xs text-neutral-500">Last updated: <!-- -->November 18, 2025</p><p class="text-xs text-neutral-500 flex items-center"><a href="https://github.com/xyjoey/PRISM" target="_blank" rel="noopener noreferrer">Built with PRISM</a><span class="ml-2">ðŸš€</span></p></div></div></footer></div><script src="/_next/static/chunks/webpack-679b75d1c4c2027c.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[3719,[\"161\",\"static/chunks/161-26b68443731f0363.js\",\"874\",\"static/chunks/874-196dbf0660d69360.js\",\"560\",\"static/chunks/560-dc25b2d8b8d763b3.js\",\"177\",\"static/chunks/app/layout-282c794e5abd4727.js\"],\"ThemeProvider\"]\n3:I[768,[\"161\",\"static/chunks/161-26b68443731f0363.js\",\"874\",\"static/chunks/874-196dbf0660d69360.js\",\"560\",\"static/chunks/560-dc25b2d8b8d763b3.js\",\"177\",\"static/chunks/app/layout-282c794e5abd4727.js\"],\"default\"]\n4:I[7555,[],\"\"]\n5:I[1295,[],\"\"]\n6:I[2548,[\"161\",\"static/chunks/161-26b68443731f0363.js\",\"874\",\"static/chunks/874-196dbf0660d69360.js\",\"560\",\"static/chunks/560-dc25b2d8b8d763b3.js\",\"177\",\"static/chunks/app/layout-282c794e5abd4727.js\"],\"default\"]\n7:I[7437,[\"161\",\"static/chunks/161-26b68443731f0363.js\",\"679\",\"static/chunks/679-23c4484ac046c23c.js\",\"874\",\"static/chunks/874-196dbf0660d69360.js\",\"748\",\"static/chunks/748-390a51461d87cd71.js\",\"974\",\"static/chunks/app/page-79095d1491d82e47.js\"],\"default\"]\n8:I[9507,[\"161\",\"static/chunks/161-26b68443731f0363.js\",\"679\",\"static/chunks/679-23c4484ac046c23c.js\",\"874\",\"static/chunks/874-196dbf0660d69360.js\",\"748\",\"static/chunks/748-390a51461d87cd71.js\",\"974\",\"static/chunks/app/page-79095d1491d82e47.js\"],\"default\"]\n9:I[1990,[\"161\",\"static/chunks/161-26b68443731f0363.js\",\"679\",\"static/chunks/679-23c4484ac046c23c.js\",\"874\",\"static/chunks/874-196dbf0660d69360.js\",\"748\",\"static/chunks/748-390a51461d87cd71.js\",\"974\",\"static/chunks/app/page-79095d1491d82e47.js\"],\"default\"]\na:I[5218,[\"161\",\"static/chunks/161-26b68443731f0363.js\",\"679\",\"static/chunks/679-23c4484ac046c23c.js\",\"874\",\"static/chunks/874-196dbf0660d69360.js\",\"748\",\"static/chunks/748-390a51461d87cd71.js\",\"974\",\"static/chunks/app/page-79095d1491d82e47.js\"],\"default\"]\nb:I[7346,[\"161\",\"static/chunks/161-26b68443731f0363.js\",\"679\",\"static/chunks/679-23c4484ac046c23c.js\",\"874\",\"static/chunks/874-196dbf0660d69360.js\",\"748\",\"static/chunks/748-390a51461d87cd71.js\",\"974\",\"static/chunks/app/page-79095d1491d82e47.js\"],\"default\"]\nc:I[9665,[],\"MetadataBoundary\"]\ne:I[9665,[],\"OutletBoundary\"]\n11:I"])</script><script>self.__next_f.push([1,"[4911,[],\"AsyncMetadataOutlet\"]\n13:I[9665,[],\"ViewportBoundary\"]\n15:I[6614,[],\"\"]\n:HL[\"/_next/static/css/8d8cb1d19c5af398.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"aGbRtuhlPdTb62nTUSBA7\",\"p\":\"\",\"c\":[\"\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/8d8cb1d19c5af398.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"scroll-smooth\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/favicon.png\",\"type\":\"image/svg+xml\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://google-fonts.jialeliu.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://google-fonts.jialeliu.com\",\"crossOrigin\":\"\"}],[\"$\",\"link\",null,{\"rel\":\"preload\",\"as\":\"style\",\"href\":\"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700\u0026family=Crimson+Text:ital,wght@0,400;0,600;1,400\u0026display=swap\"}],[\"$\",\"link\",null,{\"rel\":\"stylesheet\",\"id\":\"gfonts-css\",\"href\":\"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700\u0026family=Crimson+Text:ital,wght@0,400;0,600;1,400\u0026display=swap\",\"media\":\"print\"}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              (function(){\\n                var l = document.getElementById('gfonts-css');\\n                if (!l) return;\\n                if (l.media !== 'all') {\\n                  l.addEventListener('load', function(){ try { l.media = 'all'; } catch(e){} });\\n                }\\n              })();\\n            \"}}],[\"$\",\"noscript\",null,{\"children\":[\"$\",\"link\",null,{\"rel\":\"stylesheet\",\"href\":\"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700\u0026family=Crimson+Text:ital,wght@0,400;0,600;1,400\u0026display=swap\"}]}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              try {\\n                const theme = localStorage.getItem('theme-storage');\\n                const parsed = theme ? JSON.parse(theme) : null;\\n                const setting = parsed?.state?.theme || 'system';\\n                const prefersDark = typeof window !== 'undefined' \u0026\u0026 window.matchMedia \u0026\u0026 window.matchMedia('(prefers-color-scheme: dark)').matches;\\n                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));\\n                var root = document.documentElement;\\n                root.classList.add(effective);\\n                root.setAttribute('data-theme', effective);\\n              } catch (e) {\\n                var root = document.documentElement;\\n                root.classList.add('light');\\n                root.setAttribute('data-theme', 'light');\\n              }\\n            \"}}]]}],[\"$\",\"body\",null,{\"className\":\"font-sans antialiased\",\"children\":[\"$\",\"$L2\",null,{\"children\":[[\"$\",\"$L3\",null,{\"items\":[{\"title\":\"About\",\"type\":\"page\",\"target\":\"about\",\"href\":\"/\"},{\"title\":\"Publications\",\"type\":\"page\",\"target\":\"publications\",\"href\":\"/publications\"},{\"title\":\"Teaching\",\"type\":\"page\",\"target\":\"teaching\",\"href\":\"/teaching\"}],\"siteTitle\":\"Di Huang\",\"enableOnePageMode\":false}],[\"$\",\"main\",null,{\"className\":\"min-h-screen pt-16 lg:pt-20\",\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"$L6\",null,{\"lastUpdated\":\"November 18, 2025\"}]]}]}]]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"div\",null,{\"className\":\"max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-8 bg-background min-h-screen\",\"children\":[[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 lg:grid-cols-3 gap-12\",\"children\":[[\"$\",\"div\",null,{\"className\":\"lg:col-span-1\",\"children\":[\"$\",\"$L7\",null,{\"author\":{\"name\":\"Di Huang\",\"title\":\"Associate Professor\",\"institution\":\"ICT, CAS\",\"avatar\":\"/bio.jpg\"},\"social\":{\"email\":\"huangdi@ict.ac.cn\",\"location\":\"Beijing, China\",\"location_url\":\"https://maps.google.com\",\"location_details\":[\"Beijing, China\"],\"google_scholar\":\"https://scholar.google.com/citations?user=i27zCWQAAAAJ\u0026hl=en\u0026oi=sra\",\"github\":\"https://github.com/huangdi95\"},\"features\":{\"enable_likes\":true,\"enable_one_page_mode\":false},\"researchInterests\":[\"Automated Chip Design\",\"Program Synthesis and Code Generation\",\"Large Language Models\"]}]}],[\"$\",\"div\",null,{\"className\":\"lg:col-span-2 space-y-8\",\"children\":[[\"$\",\"section\",\"about\",{\"id\":\"about\",\"className\":\"scroll-mt-24 space-y-8\",\"children\":[[[\"$\",\"$L8\",\"about\",{\"content\":\"I am an Associate Professor at Institute of Computing Technology, Chinese Academy of Sciences (ICT, CAS). I received my B.S. in Physics from Tsinghua University and my Ph.D. from ICT, CAS. My research focuses on automated chip design and code generation, with particular interest in **systematically training chip design foundation models and building practical chip design systems powered by these models**. I am also broadly interested in **Embodied AI**.\\n\\nI am the lead contributor to the [CodeV series](https://yyyangzhao.github.io/CodeV-Series/), a family of fully open-source foundation models for HDL (e.g., Verilog) generation.\\n\\nFeel free to reach me at **huangdi\\\\[AT\\\\]ict.ac.cn**.\",\"title\":\"About\"}],[\"$\",\"$L9\",\"news\",{\"items\":[{\"date\":\"2025-11\",\"content\":\"4 papers were accepted to [AAAI 2026](https://aaai.org/conference/aaai/aaai-26/) \u003cred\u003e(2 oral)\u003c/red\u003e ðŸŽ‰\"},{\"date\":\"2025-10\",\"content\":\"2 papers were accepted to [IEEE TCAD](https://ieee-ceda.org/publications/tcad/) ðŸŽ‰\"},{\"date\":\"2025-09\",\"content\":\"We have open-sourced our HDL generation foundation models [CodeV series](https://huggingface.co/collections/zhuyaoyu/codev-series) on [ðŸ¤—Hugging Face](https://huggingface.co/), along with their [datasets](https://huggingface.co/collections/zhuyaoyu/codev-series)ðŸ”¥ðŸ”¥ðŸ”¥ \"},{\"date\":\"2025-09\",\"content\":\"4 papers were accepted to [NeurIPS 2025](https://neurips.cc/Conferences/2025) \u003cred\u003e(1 spotlight)\u003c/red\u003e ðŸŽ‰\"}],\"title\":\"News\"}],[\"$\",\"$La\",\"featured_publications\",{\"publications\":[{\"id\":\"wu2025stepfun\",\"title\":\"StepFun-Formalizer: Unlocking the Autoformalization Potential of LLMs through Knowledge-Reasoning Fusion\",\"authors\":[{\"name\":\"Yutong Wu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Di Huang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ruosi Wan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yue Peng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shijie Shang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Chenrui Cao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Lei Qi\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Rui Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zidong Du\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jie Yan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xing Hu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2026,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$0:f:0:1:2:children:1:props:children:0:props:children:0:props:children:1:props:children:0:props:children:0:2:props:publications:0:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"AAAI 2026 Oral\",\"conference\":\"\",\"paperlink\":\"https://arxiv.org/abs/2508.04440\",\"model\":\"https://huggingface.co/collections/stepfun-ai/stepfun-formalizer\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"stepfun-formalizer.png\",\"bibtex\":\"@article{wu2025stepfun,\\n  title = {StepFun-Formalizer: Unlocking the Autoformalization Potential of LLMs through Knowledge-Reasoning Fusion},\\n  author = {Wu, Yutong and Huang, Di and Wan, Ruosi and Peng, Yue and Shang, Shijie and Cao, Chenrui and Qi, Lei and Zhang, Rui and Du, Zidong and Yan, Jie and Hu, Xing},\\n  journal = {AAAI 2026 Oral},\\n  year = {2026},\\n  paperlink = {https://arxiv.org/abs/2508.04440},\\n  model = {https://huggingface.co/collections/stepfun-ai/stepfun-formalizer}\\n}\"},{\"id\":\"li2025agon\",\"title\":\"AGON: Automated Design Framework for Customizing Processors from ISA Documents\",\"authors\":[{\"name\":\"Chongxiao Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Di Huang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Pengwei Jin\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Tianyun Ma\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Husheng Han\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shuyao Cheng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yifan Hao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yongwei Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Guanglin Xu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zidong Du\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Rui Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xiaqing Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yuanbo Wen\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xing Hu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Qi Guo\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$0:f:0:1:2:children:1:props:children:0:props:children:0:props:children:1:props:children:0:props:children:0:2:props:publications:1:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"IEEE TCAD 2025\",\"conference\":\"\",\"paperlink\":\"https://arxiv.org/abs/2412.20954\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"agon.png\",\"bibtex\":\"@article{li2025agon,\\n  title = {AGON: Automated Design Framework for Customizing Processors from ISA Documents},\\n  author = {Li, Chongxiao and Huang, Di and Jin, Pengwei and Ma, Tianyun and Han, Husheng and Cheng, Shuyao and Hao, Yifan and Zhao, Yongwei and Xu, Guanglin and Du, Zidong and Zhang, Rui and Li, Xiaqing and Wen, Yuanbo and Hu, Xing and Guo, Qi },\\n  journal = {IEEE TCAD 2025},\\n  year = {2025},\\n  publisher = {IEEE},\\n  paperlink = {https://arxiv.org/abs/2412.20954}\\n}\"},{\"id\":\"dang2025miggpt\",\"title\":\"MigGPT: Harnessing Large Language Models for Automated Migration of Out-of-Tree Linux Kernel Patches Across Versions\",\"authors\":[{\"name\":\"Pucheng Dang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Di Huang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Dong Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Kang Chen\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yuanbo Wen\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Qi Guo\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xing Hu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$0:f:0:1:2:children:1:props:children:0:props:children:0:props:children:1:props:children:0:props:children:0:2:props:publications:2:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"NeurIPS 2025 Spotlight\",\"conference\":\"\",\"paperlink\":\"https://arxiv.org/abs/2504.09474\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"miggpt.png\",\"bibtex\":\"@article{dang2025miggpt,\\n  title = {MigGPT: Harnessing Large Language Models for Automated Migration of Out-of-Tree Linux Kernel Patches Across Versions},\\n  author = {Dang, Pucheng and Huang, Di and Li, Dong and Chen, Kang and Wen, Yuanbo and Guo, Qi and Hu, Xing},\\n  journal = {NeurIPS 2025 Spotlight},\\n  year = {2025},\\n  paperlink = {https://arxiv.org/abs/2504.09474}\\n}\"},{\"id\":\"zhao2025codev\",\"title\":\"CodeV: Empowering LLMs with HDL Generation through Multi-Level Summarization\",\"authors\":[{\"name\":\"Yang Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Di Huang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Chongxiao Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Pengwei Jin\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Muxin Song\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yinan Xu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ziyuan Nan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Mingju Gao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Tianyun Ma\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Lei Qi\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yansong Pan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zhenxing Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Rui Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xishan Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zidong Du\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xing Hu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$0:f:0:1:2:children:1:props:children:0:props:children:0:props:children:1:props:children:0:props:children:0:2:props:publications:3:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"IEEE TCAD 2025\",\"conference\":\"\",\"paperlink\":\"https://arxiv.org/abs/2407.10424v5\",\"projectpage\":\"https://iprc-dip.github.io/CodeV/\",\"data\":\"https://huggingface.co/datasets/yang-z/CodeV-All-dataset\",\"model\":\"https://huggingface.co/collections/zhuyaoyu/codev-series\",\"code\":\"https://github.com/IPRC-DIP/CodeV\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"codev.gif\",\"bibtex\":\"@article{zhao2025codev,\\n  title = {CodeV: Empowering LLMs with HDL Generation through Multi-Level Summarization},\\n  author = {Zhao, Yang and Huang, Di and Li, Chongxiao and Jin, Pengwei and Song, Muxin and Xu, Yinan and Nan, Ziyuan and Gao, Mingju and Ma, Tianyun and Qi, Lei and Pan, Yansong  and Zhang,  Zhenxing, and Zhang, Rui and Zhang, Xishan, and Du, Zidong, Guo, Qi and Hu, Xing},\\n  journal = {IEEE TCAD 2025},\\n  year = {2025},\\n  paperlink = {https://arxiv.org/abs/2407.10424v5},\\n  projectpage = {https://iprc-dip.github.io/CodeV/},\\n  data = {https://huggingface.co/datasets/yang-z/CodeV-All-dataset},\\n  model = {https://huggingface.co/collections/zhuyaoyu/codev-series},\\n  publisher = {IEEE}\\n}\"},{\"id\":\"jin2025realbench\",\"title\":\"RealBench: Benchmarking Verilog Generation Models with Real-World IP Designs\",\"authors\":[{\"name\":\"Pengwei Jin\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Di Huang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Chongxiao Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shuyao Cheng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yang Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xinyao Zheng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jiaguo Zhu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shuyi Xing\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Bohan Dou\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Rui Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zidong Du\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xing Hu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$0:f:0:1:2:children:1:props:children:0:props:children:0:props:children:1:props:children:0:props:children:0:2:props:publications:4:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"Preprint\",\"conference\":\"\",\"paperlink\":\"https://arxiv.org/abs/2507.16200\",\"data\":\"https://huggingface.co/datasets/Pengwei-Jin/RealBench\",\"code\":\"https://github.com/IPRC-DIP/RealBench\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"realbench.gif\",\"bibtex\":\"@article{jin2025realbench,\\n  title = {RealBench: Benchmarking Verilog Generation Models with Real-World IP Designs},\\n  author = {Jin, Pengwei and Huang, Di and Li, Chongxiao and Cheng, Shuyao and Zhao, Yang and Zheng, Xinyao and Zhu, Jiaguo and Xing, Shuyi and Dou, Bohan and Zhang, Rui and Du, Zidong, Guo, Qi and Hu, Xing},\\n  journal = {Preprint},\\n  year = {2025},\\n  paperlink = {https://arxiv.org/abs/2507.16200},\\n  data = {https://huggingface.co/datasets/Pengwei-Jin/RealBench},\\n  publisher = {IEEE}\\n}\"},{\"id\":\"zhu2025qimeng\",\"title\":\"QiMeng-CodeV-R1: Reasoning-Enhanced Verilog Generation\",\"authors\":[{\"name\":\"Yaoyu Zhu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Di Huang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Hanqi Lyu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xiaoyun Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Chongxiao Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenxuan Shi\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yutong Wu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jianan Mu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jinghua Wang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Pengwei Jin\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shuyao Cheng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shengwen Liang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xishan Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Rui Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zidong Du\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Qi Guo\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xing Hu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yunji Chen\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"conference\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$0:f:0:1:2:children:1:props:children:0:props:children:0:props:children:1:props:children:0:props:children:0:2:props:publications:5:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"\",\"conference\":\"NeurIPS 2025\",\"paperlink\":\"https://arxiv.org/abs/2505.24183\",\"projectpage\":\"https://iprc-dip.github.io/CodeV-R1/\",\"data\":\"https://huggingface.co/datasets/zhuyaoyu/CodeV-R1-dataset\",\"model\":\"https://huggingface.co/collections/zhuyaoyu/codev-series\",\"code\":\"https://github.com/IPRC-DIP/CodeV-R1\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"codev-r1.png\",\"bibtex\":\"@inproceedings{zhu2025qimeng,\\n  title = {QiMeng-CodeV-R1: Reasoning-Enhanced Verilog Generation},\\n  author = {Zhu, Yaoyu and Huang, Di and Lyu, Hanqi and Zhang, Xiaoyun and Li, Chongxiao and Shi, Wenxuan and Wu, Yutong and Mu, Jianan and Wang, Jinghua and Jin, Pengwei and Cheng, Shuyao and Liang, Shengwen and Zhang, Xishan and Zhang, Rui and Du, Zidong and Guo, Qi and Hu, Xing and Chen, Yunji},\\n  booktitle = {NeurIPS 2025},\\n  year = {2025},\\n  paperlink = {https://arxiv.org/abs/2505.24183},\\n  projectpage = {https://iprc-dip.github.io/CodeV-R1/},\\n  data = {https://huggingface.co/datasets/zhuyaoyu/CodeV-R1-dataset},\\n  model = {https://huggingface.co/collections/zhuyaoyu/codev-series}\\n}\"},{\"id\":\"huang2023anpl\",\"title\":\"ANPL: Towards Natural Programming with Interactive Decomposition\",\"authors\":[{\"name\":\"Di Huang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ziyuan Nan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xing Hu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Pengwei Jin\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shaohui Peng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yuanbo Wen\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Rui Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zidong Du\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Qi Guo\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yewen Pu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yunji Chen\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2023,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$0:f:0:1:2:children:1:props:children:0:props:children:0:props:children:1:props:children:0:props:children:0:2:props:publications:6:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"NeurIPS 2023\",\"conference\":\"\",\"volume\":\"36\",\"pages\":\"69404--69440\",\"paperlink\":\"https://arxiv.org/abs/2305.18498\",\"projectpage\":\"https://iprc-dip.github.io/ANPL/\",\"data\":\"https://github.com/IPRC-DIP/DARC/releases/tag/dataset\",\"code\":\"https://github.com/IPRC-DIP/ANPL\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"anpl.png\",\"bibtex\":\"@article{huang2023anpl,\\n  title = {ANPL: Towards Natural Programming with Interactive Decomposition},\\n  author = {Huang, Di and Nan, Ziyuan and Hu, Xing and Jin, Pengwei and Peng, Shaohui and Wen, Yuanbo and Zhang, Rui and Du, Zidong and Guo, Qi and Pu, Yewen and Chen, Yunji},\\n  journal = {NeurIPS 2023},\\n  volume = {36},\\n  pages = {69404--69440},\\n  year = {2023},\\n  paperlink = {https://arxiv.org/abs/2305.18498},\\n  projectpage = {https://iprc-dip.github.io/ANPL/},\\n  data = {https://github.com/IPRC-DIP/DARC/releases/tag/dataset}\\n}\"},{\"id\":\"huang2022neural\",\"title\":\"Neural Program Synthesis with Query\",\"authors\":[{\"name\":\"Di Huang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Rui Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xing Hu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xishan Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Pengwei Jin\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Nan Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zidong Du\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Qi Guo\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yunji Chen\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2022,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$0:f:0:1:2:children:1:props:children:0:props:children:0:props:children:1:props:children:0:props:children:0:2:props:publications:7:tags\",\"researchArea\":\"neural-networks\",\"journal\":\"ICLR 2022\",\"conference\":\"\",\"paperlink\":\"https://arxiv.org/abs/2205.07857\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"query.png\",\"bibtex\":\"@article{huang2022neural,\\n  title = {Neural Program Synthesis with Query},\\n  author = {Huang, Di and Zhang, Rui and Hu, Xing and Zhang, Xishan and Jin, Pengwei and Li, Nan and Du, Zidong and Guo, Qi and Chen, Yunji},\\n  journal = {ICLR 2022},\\n  year = {2022},\\n  paperlink = {https://arxiv.org/abs/2205.07857}\\n}\"}],\"title\":\"Selected Publications\",\"enableOnePageMode\":false}],[\"$\",\"$L9\",\"services\",{\"items\":[{\"date\":\"Reviewer\",\"content\":\"Neurips 2023-, ICLR 2024-, ICML 2024-, AAAI 2025-, AISTATS 2025\"},{\"date\":\"Organizing Committee\",\"content\":\"[AI for Fully-Automated Chip Design (AI4FACD) Workshop](https://ai4facd.github.io/2024/) @ [ISCA 2024](https://iscaconf.org/isca2024/)\"}],\"title\":\"Services\"}],[\"$\",\"$L9\",\"invited_talks\",{\"items\":[{\"date\":\"2025-09\",\"content\":\"LLM for Hardware Code Generation and Optimization @ [CCF ADL](https://conf.ccf.org.cn/web/api/m1406937421697912832175548162096.action)\"},{\"date\":\"2025-06\",\"content\":\"QiMeng: Automated Hardware and Software Design for Processor Chip @ [AI4FACD Workshop](https://ai4facd.github.io/2025/) @ [ISCA 2025](https://iscaconf.org/isca2025/): \"}],\"title\":\"Invited Talks\"}]],false,false,false]}]]}]]}],[\"$\",\"$Lb\",null,{}]]}],[\"$\",\"$Lc\",null,{\"children\":\"$Ld\"}],null,[\"$\",\"$Le\",null,{\"children\":[\"$Lf\",\"$L10\",[\"$\",\"$L11\",null,{\"promise\":\"$@12\"}]]}]]}],{},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"vYo7dqQrmdE-6fa9N_Vcm\",{\"children\":[[\"$\",\"$L13\",null,{\"children\":\"$L14\"}],null]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$15\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"16:\"$Sreact.suspense\"\n17:I[4911,[],\"AsyncMetadata\"]\nd:[\"$\",\"$16\",null,{\"fallback\":null,\"children\":[\"$\",\"$L17\",null,{\"promise\":\"$@18\"}]}]\n"])</script><script>self.__next_f.push([1,"10:null\n"])</script><script>self.__next_f.push([1,"14:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\nf:null\n"])</script><script>self.__next_f.push([1,"18:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Di Huang\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Associate Professor at ICT, CAS.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"author\",\"content\":\"Di Huang\"}],[\"$\",\"meta\",\"3\",{\"name\":\"keywords\",\"content\":\"Di Huang,PhD,Research,ICT, CAS\"}],[\"$\",\"meta\",\"4\",{\"name\":\"creator\",\"content\":\"Di Huang\"}],[\"$\",\"meta\",\"5\",{\"name\":\"publisher\",\"content\":\"Di Huang\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:title\",\"content\":\"Di Huang\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:description\",\"content\":\"Associate Professor at ICT, CAS.\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:site_name\",\"content\":\"Di Huang's Academic Website\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"11\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:title\",\"content\":\"Di Huang\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:description\",\"content\":\"Associate Professor at ICT, CAS.\"}],[\"$\",\"link\",\"14\",{\"rel\":\"icon\",\"href\":\"/favicon.png\"}]],\"error\":null,\"digest\":\"$undefined\"}\n12:{\"metadata\":\"$18:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>